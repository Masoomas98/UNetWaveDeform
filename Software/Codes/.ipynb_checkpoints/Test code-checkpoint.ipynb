{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62d47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import gzip\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast \n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb408021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data: (753, 251)\n"
     ]
    }
   ],
   "source": [
    "# Load train and test data from files\n",
    "train_waveforms = np.genfromtxt('Data/trainset.csv', delimiter=',')\n",
    "train_times = np.genfromtxt('Data/traintime.csv', delimiter=',')\n",
    "test_waveforms = np.genfromtxt('Data/testset.csv', delimiter=',')\n",
    "test_times = np.genfromtxt('Data/testtime.csv', delimiter=',')\n",
    "\n",
    "# Concatenate train and test data along the first axis\n",
    "all_waveforms = np.concatenate((train_waveforms, test_waveforms), axis=0)\n",
    "all_times = np.concatenate((train_times, test_times), axis=0)\n",
    "\n",
    "# Print the shapes of the concatenated datasets\n",
    "#print('All waveforms:', all_waveforms.shape)\n",
    "#print('All times:', all_times.shape)\n",
    "\n",
    "# Reshape the time array to be a column vector\n",
    "all_times = all_times.reshape(-1, 1)\n",
    "\n",
    "# Define the threshold for signal detection\n",
    "#threshold = 0.1\n",
    "\n",
    "# Apply thresholding to the all_times array         # to convert time into 0s and 1s\n",
    "#all_times = np.where(all_times > threshold, 1, 0)\n",
    "\n",
    "# Print the resulting array\n",
    "#print(all_times)\n",
    "\n",
    "# Concatenate the waveform and time arrays along the second axis\n",
    "all_data = np.concatenate((all_waveforms, all_times), axis=1)\n",
    "\n",
    "# Print the shape of the concatenated dataset\n",
    "print('All data:', all_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d541f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807cbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_waveforms, all_times, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db912241",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#We can define the CNN architecture using the Sequential() function from Keras. \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D, MaxPooling1D, Flatten, Dense\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.model'"
     ]
    }
   ],
   "source": [
    "#We can define the CNN architecture using the Sequential() function from Keras. \n",
    "\n",
    "from keras.model import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0eb3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#defining the CNN Model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m250\u001b[39m,\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPoolingD(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#defining the CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(250,1)))\n",
    "model.add(MaxPoolingD(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1d(filters=128, kernel_size=3, actiavtion='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e399e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(250, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) what is activation=relu and this code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
